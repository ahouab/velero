<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Velero</title>
    <link>/docs/v0.11.0/</link>
    <description>Recent content on Velero</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/docs/v0.11.0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/about/</guid>
      <description>How Velero Works Each Velero operation &amp;ndash; on-demand backup, scheduled backup, restore &amp;ndash; is a custom resource, defined with a Kubernetes Custom Resource Definition (CRD) and stored in etcd. Velero also includes controllers that process the custom resources to perform backups, restores, and all related operations.
You can back up or restore all objects in your cluster, or you can filter objects by type, namespace, and/or label.
Velero is ideal for the disaster recovery use case, as well as for snapshotting your application state, prior to performing system operations on your cluster (e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/api-types/backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/api-types/backup/</guid>
      <description>Backup API Type Use The Backup API type is used as a request for the Velero Server to perform a backup. Once created, the Velero Server immediately starts the backup process.
API GroupVersion Backup belongs to the API group version velero.io/v1.
Definition Here is a sample Backup object with each of the fields documented:
# Standard Kubernetes API Version declaration. Required. apiVersion: velero.io/v1 # Standard Kubernetes Kind declaration. Required. kind: Backup # Standard Kubernetes metadata.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/api-types/backupstoragelocation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/api-types/backupstoragelocation/</guid>
      <description>Velero Backup Storage Locations Backup Storage Location Velero can store backups in a number of locations. These are represented in the cluster via the BackupStorageLocation CRD.
Velero must have at least one BackupStorageLocation. By default, this is expected to be named default, however the name can be changed by specifying --default-backup-storage-location on velero server. Backups that do not explicitly specify a storage location will be saved to this BackupStorageLocation.
 NOTE: BackupStorageLocation takes the place of the Config.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/api-types/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/api-types/README/</guid>
      <description>Table of Contents API types Here we list the API types that have some functionality that you can only configure via json/yaml vs the velero cli (hooks)
  Backup  BackupStorageLocation  VolumeSnapshotLocation  </description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/api-types/volumesnapshotlocation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/api-types/volumesnapshotlocation/</guid>
      <description>Velero Volume Snapshot Location Volume Snapshot Location A volume snapshot location is the location in which to store the volume snapshots created for a backup.
Velero can be configured to take snapshots of volumes from multiple providers. Velero also allows you to configure multiple possible VolumeSnapshotLocation per provider, although you can only select one location per provider at backup time.
Each VolumeSnapshotLocation describes a provider + location. These are represented in the cluster via the VolumeSnapshotLocation CRD.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/aws-config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/aws-config/</guid>
      <description>Run Velero on AWS To set up Velero on AWS, you:
 Download an official release of Velero Create your S3 bucket Create an AWS IAM user for Velero Configure the server Create a Secret for your credentials  If you do not have the aws CLI locally installed, follow the user guide to set it up.
Download Velero   Download the latest release&amp;rsquo;s tarball for your client platform.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/azure-config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/azure-config/</guid>
      <description>Run Velero on Azure To configure Velero on Azure, you:
 Download an official release of Velero Create your Azure storage account and blob container Create Azure service principal for Velero Configure the server Create a Secret for your credentials  If you do not have the az Azure CLI 2.0 installed locally, follow the install guide to set it up.
Run:
az login Kubernetes cluster prerequisites Ensure that the VMs for your agent pool allow Managed Disks.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/build-from-scratch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/build-from-scratch/</guid>
      <description>Build from source   Prerequisites  Getting the source  Build  Test  Run  Vendoring dependencies  Prerequisites  Access to a Kubernetes cluster, version 1.7 or later. Version 1.7.5 or later is required to run velero backup delete. A DNS server on the cluster kubectl installed  Go installed (minimum version 1.8)  Getting the source Option 1) Get latest (recommended) mkdir $HOME/go export GOPATH=$HOME/go go get github.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/debugging-install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/debugging-install/</guid>
      <description>Debugging Installation Issues General invalid configuration: no configuration has been provided This typically means that no kubeconfig file can be found for the Velero client to use. Velero looks for a kubeconfig in the following locations:
 the path specified by the --kubeconfig flag, if any the path specified by the $KUBECONFIG environment variable, if any ~/.kube/config  Backups or restores stuck in New phase This means that the Velero controllers are not processing the backups/restores, which usually happens because the Velero server is not running.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/debugging-restores/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/debugging-restores/</guid>
      <description>Debugging Restores   Example  Structure  Example When Velero finishes a Restore, its status changes to &amp;ldquo;Completed&amp;rdquo; regardless of whether or not there are issues during the process. The number of warnings and errors are indicated in the output columns from velero restore get:
NAME BACKUP STATUS WARNINGS ERRORS CREATED SELECTOR backup-test-20170726180512 backup-test Completed 155 76 2017-07-26 11:41:14 -0400 EDT &amp;lt;none&amp;gt; backup-test-20170726180513 backup-test Completed 121 14 2017-07-26 11:48:24 -0400 EDT &amp;lt;none&amp;gt; backup-test-2-20170726180514 backup-test-2 Completed 0 0 2017-07-26 13:31:21 -0400 EDT &amp;lt;none&amp;gt; backup-test-2-20170726180515 backup-test-2 Completed 0 1 2017-07-26 13:32:59 -0400 EDT &amp;lt;none&amp;gt; To delve into the warnings and errors into more detail, you can use velero restore describe:</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/disaster-case/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/disaster-case/</guid>
      <description>Disaster recovery Using Schedules and Restore-Only Mode
If you periodically back up your cluster&amp;rsquo;s resources, you are able to return to a previous state in case of some unexpected mishap, such as a service outage. Doing so with Velero looks like the following:
  After you first run the Velero server on your cluster, set up a daily backup (replacing &amp;lt;SCHEDULE NAME&amp;gt; in the command as desired):
velero schedule create &amp;lt;SCHEDULE NAME&amp;gt; --schedule &amp;quot;0 7 * * *&amp;quot; This creates a Backup object with the name &amp;lt;SCHEDULE NAME&amp;gt;-&amp;lt;TIMESTAMP&amp;gt;.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/expose-minio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/expose-minio/</guid>
      <description>Expose Minio outside your cluster When you run commands to get logs or describe a backup, the Velero server generates a pre-signed URL to download the requested items. To access these URLs from outside the cluster &amp;ndash; that is, from your Velero client &amp;ndash; you need to make Minio available outside the cluster. You can:
 Change the Minio Service type from ClusterIP to NodePort. Set up Ingress for your cluster, keeping Minio Service type ClusterIP.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/extend/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/extend/</guid>
      <description>Extend Velero Velero includes mechanisms for extending the core functionality to meet your individual backup/restore needs:
  Hooks allow you to specify commands to be executed within running pods during a backup. This is useful if you need to run a workload-specific command prior to taking a backup (for example, to flush disk buffers or to freeze a database).  Plugins allow you to develop custom object/block storage back-ends or per-item backup/restore actions that can execute arbitrary logic, including modifying the items being backed up/restored.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/faq/</guid>
      <description>FAQ When is it appropriate to use Velero instead of etcd&amp;rsquo;s built in backup/restore? Etcd&amp;rsquo;s backup/restore tooling is good for recovering from data loss in a single etcd cluster. For example, it is a good idea to take a backup of etcd prior to upgrading etcd itself. For more sophisticated management of your Kubernetes cluster backups and restores, we feel that Velero is generally a better approach. It gives you the ability to throw away an unstable cluster and restore your Kubernetes resources and data into a new cluster, which you can&amp;rsquo;t do easily just by backing up and restoring etcd.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/gcp-config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/gcp-config/</guid>
      <description>Run Velero on GCP You can run Kubernetes on Google Cloud Platform in either:
 Kubernetes on Google Compute Engine virtual machines Google Kubernetes Engine  If you do not have the gcloud and gsutil CLIs locally installed, follow the user guide to set them up.
Download Velero   Download the latest release&amp;rsquo;s tarball for your client platform.
  Extract the tarball:
tar -xvf &amp;lt;RELEASE-TARBALL-NAME&amp;gt;.tar.gz -C /dir/to/extract/to We&amp;rsquo;ll refer to the directory you extracted to as the &amp;ldquo;Velero directory&amp;rdquo; in subsequent steps.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/get-started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/get-started/</guid>
      <description>Getting started The following example sets up the Velero server and client, then backs up and restores a sample application.
For simplicity, the example uses Minio, an S3-compatible storage service that runs locally on your cluster. For additional functionality with this setup, see the docs on how to expose Minio outside your cluster.
NOTE The example lets you explore basic Velero functionality. Configuring Minio for production is out of scope.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/hooks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/hooks/</guid>
      <description>Hooks Velero currently supports executing commands in containers in pods during a backup.
Backup Hooks When performing a backup, you can specify one or more commands to execute in a container in a pod when that pod is being backed up.
Velero versions prior to v0.7.0 only support hooks that execute prior to any custom action processing (&amp;ldquo;pre&amp;rdquo; hooks).
As of version v0.7.0, Velero also supports &amp;ldquo;post&amp;rdquo; hooks - these execute after all custom actions have completed, as well as after all the additional items specified by custom actions have been backed up.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/ibm-config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/ibm-config/</guid>
      <description>Use IBM Cloud Object Storage as Velero&amp;rsquo;s storage destination. You can deploy Velero on IBM Public or Private clouds, or even on any other Kubernetes cluster, but anyway you can use IBM Cloud Object Store as a destination for Velero&amp;rsquo;s backups.
To set up IBM Cloud Object Storage (COS) as Velero&amp;rsquo;s destination, you:
 Download an official release of Velero Create your COS instance Create an S3 bucket Define a service that can store data in the bucket Configure and start the Velero server  Download Velero   Download the latest release&amp;rsquo;s tarball for your client platform.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/image-tagging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/image-tagging/</guid>
      <description>Image tagging policy This document describes Velero&amp;rsquo;s image tagging policy.
Released versions gcr.io/heptio-images/velero:&amp;lt;SemVer&amp;gt;
Velero follows the Semantic Versioning standard for releases. Each tag in the github.com/heptio/velero repository has a matching image, e.g. gcr.io/heptio-images/velero:v0.11.0.
Latest gcr.io/heptio-images/velero:latest
The latest tag follows the most recently released version of Velero.
Development gcr.io/heptio-images/velero:master
The master tag follows the latest commit to land on the master branch.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/img/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/img/README/</guid>
      <description>Some of these diagrams (for instance backup-process.png), have been created on draw.io, using the &amp;ldquo;Include a copy of my diagram&amp;rdquo; option. If you want to make changes to these diagrams, try importing them into draw.io, and you should have access to the original shapes/text that went into the originals.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/install-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/install-overview/</guid>
      <description>Set up Velero on your platform You can run Velero with a cloud provider or on-premises. For detailed information about the platforms that Velero supports, see Compatible Storage Providers.
In version 0.7.0 and later, you can run Velero in any namespace, which requires additional customization. See Run in custom namespace.
In version 0.9.0 and later, you can use Velero&amp;rsquo;s integration with restic, which requires additional setup. See restic instructions.
Customize configuration Whether you run Velero on a cloud provider or on-premises, if you have more than one volume snapshot location for a given volume provider, you can specify its default location for backups by setting a server flag in your Velero deployment YAML.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/locations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/locations/</guid>
      <description>Backup Storage Locations and Volume Snapshot Locations Velero v0.10 introduces a new way of configuring where Velero backups and their associated persistent volume snapshots are stored.
Motivations In Velero versions prior to v0.10, the configuration for where to store backups &amp;amp; volume snapshots is specified in a Config custom resource. The backupStorageProvider section captures the place where all Velero backups should be stored. This is defined by a provider (e.g. aws, azure, gcp, minio, etc.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/migrating-to-velero/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/migrating-to-velero/</guid>
      <description>Migrating from Heptio Ark to Velero As of v0.11.0, Heptio Ark has become Velero. This means the following changes have been made:
 The ark CLI client is now velero. The default Kubernetes namespace and ServiceAccount are now named velero (formerly heptio-ark). The container image name is now gcr.io/heptio-images/velero (formerly gcr.io/heptio-images/ark). CRDs are now under the new velero.io API group name (formerly ark.heptio.com).  The following instructions will help you migrate your existing Ark installation to Velero.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/migration-case/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/migration-case/</guid>
      <description>Cluster migration Using Backups and Restores
Velero can help you port your resources from one cluster to another, as long as you point each Velero instance to the same cloud object storage location. In this scenario, we are also assuming that your clusters are hosted by the same cloud provider. Note that Velero does not support the migration of persistent volumes across cloud providers.
  (Cluster 1) Assuming you haven&amp;rsquo;t already been checkpointing your data with the Velero schedule operation, you need to first back up your entire cluster (replacing &amp;lt;BACKUP-NAME&amp;gt; as desired):</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/namespace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/namespace/</guid>
      <description>Run in custom namespace In Velero version 0.7.0 and later, you can run Velero in any namespace. To do so, you specify the namespace in the YAML files that configure the Velero server. You then also specify the namespace when you run Velero client commands.
Edit the example files The Velero release tarballs include a set of example configs that you can use to set up your Velero server. The examples place the server and backup/schedule/restore/etc.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/output-file-format/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/output-file-format/</guid>
      <description>Output file format A backup is a gzip-compressed tar file whose name matches the Backup API resource&amp;rsquo;s metadata.name (what is specified during velero backup create &amp;lt;NAME&amp;gt;).
In cloud object storage, each backup file is stored in its own subdirectory in the bucket specified in the Velero server configuration. This subdirectory includes an additional file called velero-backup.json. The JSON file lists all information about your associated Backup resource, including any default values.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/plugins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/plugins/</guid>
      <description>Plugins Velero has a plugin architecture that allows users to add their own custom functionality to Velero backups &amp;amp; restores without having to modify/recompile the core Velero binary. To add custom functionality, users simply create their own binary containing implementations of Velero&amp;rsquo;s plugin kinds (described below), plus a small amount of boilerplate code to expose the plugin implementations to Velero. This binary is added to a container image that serves as an init container for the Velero server pod and copies the binary into a shared emptyDir volume for the Velero server to access.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/rbac/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/rbac/</guid>
      <description>Run Velero more securely with restrictive RBAC settings By default Velero runs with an RBAC policy of ClusterRole cluster-admin. This is to make sure that Velero can back up or restore anything in your cluster. But cluster-admin access is wide open &amp;ndash; it gives Velero components access to everything in your cluster. Depending on your environment and your security needs, you should consider whether to configure additional RBAC policies with more restrictive access.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/restic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/restic/</guid>
      <description>Restic Integration As of version 0.9.0, Velero has support for backing up and restoring Kubernetes volumes using a free open-source backup tool called restic.
Velero has always allowed you to take snapshots of persistent volumes as part of your backups if you’re using one of the supported cloud providers’ block storage offerings (Amazon EBS Volumes, Azure Managed Disks, Google Persistent Disks). Starting with version 0.6.0, we provide a plugin model that enables anyone to implement additional object and block storage backends, outside the main Velero repository.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/support-matrix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/support-matrix/</guid>
      <description>Compatible Storage Providers Velero supports a variety of storage providers for different backup and snapshot operations. As of version 0.6.0, a plugin system allows anyone to add compatibility for additional backup and volume storage platforms without modifying the Velero codebase.
Backup Storage Providers    Provider Owner Contact      AWS S3 Velero Team  Slack, GitHub Issue    Azure Blob Storage Velero Team  Slack, GitHub Issue    Google Cloud Storage Velero Team  Slack, GitHub Issue    S3-Compatible Backup Storage Providers Velero uses Amazon&amp;rsquo;s Go SDK to connect to the S3 API.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/troubleshooting/</guid>
      <description>Troubleshooting These tips can help you troubleshoot known issues. If they don&amp;rsquo;t help, you can file an issue, or talk to us on the #velero channel on the Kubernetes Slack server.
See also:
  Debug installation/setup issues  Debug restores  General troubleshooting information In velero version &amp;gt;= 0.10.0, you can use the velero bug command to open a Github issue by launching a browser window with some prepopulated values.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/vendoring-dependencies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/vendoring-dependencies/</guid>
      <description>Vendoring dependencies Overview We are using dep to manage dependencies. You can install it by following these instructions.
Adding a new dependency Run dep ensure. If you want to see verbose output, you can append -v as in dep ensure -v.
Updating an existing dependency Run dep ensure -update &amp;lt;pkg&amp;gt; [&amp;lt;pkg&amp;gt; ...] to update one or more dependencies.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/versions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/versions/</guid>
      <description>Upgrading Velero versions Velero supports multiple concurrent versions. Whether you&amp;rsquo;re setting up Velero for the first time or upgrading to a new version, you need to pay careful attention to versioning. This doc page is new as of version 0.10.0, and will be updated with information about subsequent releases.
Minor versions, patch versions The documentation site provides docs for minor versions only, not for patch releases. Patch releases are guaranteed not to be breaking, but you should carefully read the release notes to make sure that you understand any relevant changes.</description>
    </item>
    
    <item>
      <title></title>
      <link>/docs/v0.11.0/zenhub/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/v0.11.0/zenhub/</guid>
      <description>ZenHub As an Open Source community, it is necessary for our work, communication, and collaboration to be done in the open. GitHub provides a central repository for code, pull requests, issues, and documentation. When applicable, we will use Google Docs for design reviews, proposals, and other working documents.
While GitHub issues, milestones, and labels generally work pretty well, the Velero team has found that product planning requires some additional tooling that GitHub projects do not offer.</description>
    </item>
    
  </channel>
</rss>